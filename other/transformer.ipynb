{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import face_alignment\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "dir_data = '../../data/additionnal_data_liveness'\n",
    "accepted = ['.jpg','.jpeg','.png']\n",
    "label_dict = {0:'fake', 1:'real'}\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "patience_early = 5\n",
    "factor_reduce_lr = 0.1\n",
    "patience_lr = 2\n",
    "batch_size = 128\n",
    "epoch = 25\n",
    "num_classes = 2\n",
    "\n",
    "patch_size = (2, 2)  # 2-by-2 sized patches\n",
    "dropout_rate = 0.03  # Dropout rate\n",
    "num_heads = 8  # Attention heads\n",
    "embed_dim = 64  # Embedding dimension\n",
    "num_mlp = 256  # MLP layer size\n",
    "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
    "window_size = 2  # Size of attention window\n",
    "shift_size = 1  # Size of shifting window\n",
    "image_dimension = 32  # Initial image size\n",
    "\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 40\n",
    "validation_split = 0.1\n",
    "weight_decay = 0.0001\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2358f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(open('liveness_img_seventh.npy', 'rb')).astype(np.uint8)\n",
    "labels = np.load(open('liveness_label_seventh.npy', 'rb'))\n",
    "labels = np.array([0 if i=='fake' else 1 for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deaafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "value, count = np.unique(labels, return_counts = True)\n",
    "plt.bar(['fake','real'], count)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8910aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "idx_real = np.where(labels==1)[0][idx]\n",
    "plt.imshow(data[idx_real][:,:,[2,1,0]])\n",
    "plt.title('Real')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "idx_fake = np.where(labels==0)[0][idx]\n",
    "plt.imshow(data[idx_fake][:,:,[2,1,0]])\n",
    "plt.title('Fake')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7047db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(data,\n",
    "                                        labels,\n",
    "                                        test_size=0.1,\n",
    "                                        stratify=labels,\n",
    "                                        random_state=0)\n",
    "data, labels = None, None\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                  y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=y,\n",
    "                                                  random_state=0)\n",
    "X, y = None, None\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis=-1)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a309d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an augmentation pipeline\n",
    "transform = A.Compose([A.Flip(p=0.5),\n",
    "                       A.ShiftScaleRotate(shift_limit=0.1,\n",
    "                                          scale_limit=0.10,\n",
    "                                          rotate_limit=10,\n",
    "                                          interpolation=1,\n",
    "                                          border_mode=0,\n",
    "                                          value=(0,0,0),\n",
    "                                          mask_value=0,\n",
    "                                          shift_limit_x=None,\n",
    "                                          shift_limit_y=None,\n",
    "                                          always_apply=False,\n",
    "                                          p=0.25),\n",
    "                       A.RandomBrightness(limit=0.5,\n",
    "                                          always_apply=False,\n",
    "                                          p=0.25)])\n",
    "for seed in range(1):\n",
    "    random.seed(seed)\n",
    "    for idx, (image, lbl) in enumerate(tqdm(list(zip(X_train, y_train)))):\n",
    "        X_train[idx,:,:,:] = transform(image=image.astype(np.uint8))[\"image\"]\n",
    "        y_train[idx,:] = lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd02ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_val = np_utils.to_categorical(y_val, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94400b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f63fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df73833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37d476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(windows, shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),)\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super(DropPath, self).__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x):\n",
    "        input_shape = tf.shape(x)\n",
    "        batch_size = input_shape[0]\n",
    "        rank = x.shape.rank\n",
    "        shape = (batch_size,) + (1,) * (rank - 1)\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfc50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
    "        super(WindowAttention, self).__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
    "        self.relative_position_bias_table = self.add_weight(shape=(num_window_elements, self.num_heads),\n",
    "                                                            initializer=tf.initializers.Zeros(),\n",
    "                                                            trainable=True,)\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.Variable(initial_value=tf.convert_to_tensor(relative_position_index), trainable=False)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(self.relative_position_index, shape=(-1,))\n",
    "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
    "        relative_position_bias = tf.reshape(relative_position_bias, shape=(num_window_elements, num_window_elements, -1))\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
    "            attn = (tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size)) + mask_float)\n",
    "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6cce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(self,dim,num_patch,num_heads,window_size=7,shift_size=0,num_mlp=1024,qkv_bias=True,dropout_rate=0.0,**kwargs,):\n",
    "        super(SwinTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(dim,\n",
    "                                    window_size=(self.window_size, self.window_size),\n",
    "                                    num_heads=num_heads,\n",
    "                                    qkv_bias=qkv_bias,\n",
    "                                    dropout_rate=dropout_rate,)\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential([layers.Dense(num_mlp),\n",
    "                                     layers.Activation(keras.activations.gelu),\n",
    "                                     layers.Dropout(dropout_rate),\n",
    "                                     layers.Dense(dim),\n",
    "                                     layers.Dropout(dropout_rate),])\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None),)\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None),)\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(mask_windows, shape=[-1, self.window_size * self.window_size])\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(x_windows, shape=(-1, self.window_size * self.window_size, channels))\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(attn_windows, shape=(-1, self.window_size, self.window_size, channels))\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, channels)\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ad216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ed3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtract(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super(PatchExtract, self).__init__(**kwargs)\n",
    "        self.patch_size_x = patch_size[0]\n",
    "        self.patch_size_y = patch_size[0]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(images=images,\n",
    "                                           sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "                                           strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "                                           rates=(1, 1, 1, 1),\n",
    "                                           padding=\"VALID\",)\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patch_num = patches.shape[1]\n",
    "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
    "\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super(PatchEmbedding, self).__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim):\n",
    "        super(PatchMerging, self).__init__()\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
    "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0bb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(input_shape)\n",
    "x = layers.RandomCrop(image_dimension, image_dimension)(input)\n",
    "x = layers.RandomFlip(\"horizontal\")(x)\n",
    "x = PatchExtract(patch_size)(x)\n",
    "x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
    "x = SwinTransformer(dim=embed_dim,\n",
    "                    num_patch=(num_patch_x, num_patch_y),\n",
    "                    num_heads=num_heads,\n",
    "                    window_size=window_size,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=num_mlp,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    dropout_rate=dropout_rate,)(x)\n",
    "x = SwinTransformer(dim=embed_dim,\n",
    "                    num_patch=(num_patch_x, num_patch_y),\n",
    "                    num_heads=num_heads,\n",
    "                    window_size=window_size,\n",
    "                    shift_size=shift_size,\n",
    "                    num_mlp=num_mlp,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    dropout_rate=dropout_rate,)(x)\n",
    "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "output = layers.Dense(num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5c826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5347d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(input, output)\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "                       keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),],)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009665a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbc36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a285e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87250b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
