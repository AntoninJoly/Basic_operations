{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e6aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import json\n",
    "from imantics import Mask\n",
    "from panopticapi.utils import rgb2id\n",
    "from PIL import Image\n",
    "from pycocotools import mask as coco_mask\n",
    "from seaborn import color_palette\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "palette = itertools.cycle(color_palette())\n",
    "data_dir = 'C:/Users/Antonin_Joly/Downloads/Construction_dataset/Construction_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27709737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "item = 'distribution_transformer'\n",
    "COCO_ANNO_PATH = os.path.join(data_dir, item, 'coco.json')\n",
    "COCO_IMG_PATH  = os.path.join(data_dir, item, 'images')\n",
    "\n",
    "coco = COCO(COCO_ANNO_PATH)\n",
    "\n",
    "catIDs = coco.getCatIds()\n",
    "cats = coco.loadCats(catIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be0980f-79f6-4f02-a83c-6aa15ddf7e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images containing all the  classes: 409\n"
     ]
    }
   ],
   "source": [
    "imgIds = coco.getImgIds(catIds=catIDs)\n",
    "print(\"Number of images containing all the  classes:\", len(imgIds))\n",
    "\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "I = cv2.imread(os.path.join(data_dir, item, 'images', img['file_name']))[:,:,[2,1,0]]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIDs, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52c381-a3d8-45df-acc0-1e787e21a15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f8d279-2309-46e4-8a3c-9fa912a5756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_poly_to_mask(segmentations, height, width):\n",
    "    # this function is from facebookresearch_detr_master/datasets/coco.py\n",
    "    masks = []\n",
    "    for polygons in segmentations:\n",
    "        rles = coco_mask.frPyObjects(polygons, height, width)\n",
    "        mask = coco_mask.decode(rles)\n",
    "        if len(mask.shape) < 3:\n",
    "            mask = mask[..., None]\n",
    "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        mask = mask.any(dim=2)\n",
    "        masks.append(mask)\n",
    "    if masks:\n",
    "        masks = torch.stack(masks, dim=0)\n",
    "    else:\n",
    "        masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
    "    return masks\n",
    "\n",
    "def detect_masks(im):\n",
    "    im_w, im_h = im.size\n",
    "    img = transform(im).unsqueeze(0)\n",
    "    out = model(img.to(device))\n",
    "\n",
    "    # scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n",
    "    # threshold the confidence\n",
    "    # keep = scores > 0.85\n",
    "    result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]\n",
    "\n",
    "    # The segmentation is stored in a special-format png\n",
    "    panoptic_seg = Image.open(io.BytesIO(result[\"png_string\"]))\n",
    "    panoptic_seg = np.array(panoptic_seg, dtype=np.uint8).copy()\n",
    "    # We retrieve the ids corresponding to each mask\n",
    "    panoptic_seg_id = rgb2id(panoptic_seg)\n",
    "    # Finally we color each mask individually\n",
    "    masks = []\n",
    "    for id in range(panoptic_seg_id.max() + 1):\n",
    "        panoptic_seg = np.zeros(list(panoptic_seg_id.shape) + [3])\n",
    "        panoptic_seg[panoptic_seg_id == id] = np.asarray(next(palette)) * 255\n",
    "        panoptic_seg = np.array(panoptic_seg, dtype=np.uint8)\n",
    "        panoptic_seg = cv2.cvtColor(panoptic_seg, cv2.COLOR_BGR2GRAY)\n",
    "        panoptic_seg = cv2.resize(panoptic_seg, (im_w, im_h))\n",
    "        masks.append(panoptic_seg)\n",
    "\n",
    "    return masks, result\n",
    "\n",
    "def remove_overlap(mask, lab_mask):\n",
    "    row, col = mask.shape\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if mask[i, j] != 0 and lab_mask[i, j] != 0:\n",
    "                mask[i, j] = 0\n",
    "    return mask\n",
    "\n",
    "def get_bbox_segmask(mask, h, w):\n",
    "    polygons = Mask(mask).polygons()\n",
    "    segment = []\n",
    "    for i in polygons.segmentation:\n",
    "        if len(i) > 20:\n",
    "            segment.append(i)\n",
    "    if not segment:\n",
    "        return [], []\n",
    "\n",
    "    mask = convert_coco_poly_to_mask([segment], h, w).squeeze()\n",
    "\n",
    "    bboxes = []\n",
    "    contours, _ = cv2.findContours(mask.numpy(), 1, 2)\n",
    "    for cnt in contours:\n",
    "        # M = cv2.moments(cnt)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        bboxes.append((x, y, w, h))\n",
    "\n",
    "    # combining all the bboxes to form a big bbox\n",
    "    if len(bboxes) > 0:\n",
    "        x_min, y_min, w_max, h_max = np.inf, np.inf, 0, 0\n",
    "        for x, y, w, h in bboxes:\n",
    "            if x_min > x:\n",
    "                x_min = x\n",
    "            if y_min > y:\n",
    "                y_min = y\n",
    "            if w_max < x + w:\n",
    "                w_max = x + w\n",
    "            if h_max < y + h:\n",
    "                h_max = y + h\n",
    "\n",
    "        bbox = [x_min, y_min, w_max - x_min, h_max - y_min]\n",
    "    else:\n",
    "        bbox = bboxes[0]\n",
    "    return bbox, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8f2851-3251-4cb6-a822-47f735d659ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading From aac_blocks\n",
      "finished aac_blocks: 0\n",
      "Reading From adhesives\n",
      "finished adhesives: 1\n",
      "Reading From ahus\n",
      "finished ahus: 2\n",
      "Reading From aluminium_frames_for_false_ceiling\n",
      "finished aluminium_frames_for_false_ceiling: 3\n",
      "Reading From chiller\n",
      "finished chiller: 4\n",
      "Reading From concrete_mixer_machine\n",
      "finished concrete_mixer_machine: 5\n",
      "Reading From concrete_pump\n",
      "finished concrete_pump: 6\n",
      "Reading From control_panel\n",
      "finished control_panel: 7\n",
      "Reading From cu_piping\n",
      "finished cu_piping: 8\n",
      "Reading From distribution_transformer\n",
      "finished distribution_transformer: 9\n",
      "Reading From dump_truck_tipper_truck\n",
      "finished dump_truck_tipper_truck: 10\n",
      "Reading From emulsion_paint\n",
      "finished emulsion_paint: 11\n",
      "Reading From enamel_paint\n",
      "finished enamel_paint: 12\n",
      "Reading From fine_aggregate\n",
      "finished fine_aggregate: 13\n",
      "Reading From fire_buckets\n",
      "finished fire_buckets: 14\n",
      "Reading From fire_extinguishers\n",
      "finished fire_extinguishers: 15\n",
      "Reading From glass_wool\n",
      "finished glass_wool: 16\n",
      "Reading From grader\n",
      "finished grader: 17\n",
      "Reading From hoist\n",
      "finished hoist: 18\n",
      "Reading From hollow_concrete_blocks\n",
      "finished hollow_concrete_blocks: 19\n",
      "Reading From hot_mix_plant\n",
      "finished hot_mix_plant: 20\n",
      "Reading From hydra_crane\n",
      "finished hydra_crane: 21\n",
      "Reading From interlocked_switched_socket\n",
      "finished interlocked_switched_socket: 22\n",
      "Reading From junction_box\n",
      "finished junction_box: 23\n",
      "Reading From lime\n",
      "finished lime: 24\n",
      "Reading From marble\n",
      "finished marble: 25\n",
      "Reading From metal_primer\n",
      "finished metal_primer: 26\n",
      "Reading From pipe_fittings\n",
      "finished pipe_fittings: 27\n",
      "Reading From rcc_hume_pipes\n",
      "finished rcc_hume_pipes: 28\n",
      "Reading From refrigerant_gas\n",
      "finished refrigerant_gas: 29\n",
      "Reading From river_sand\n",
      "finished river_sand: 30\n",
      "Reading From rmc_batching_plant\n",
      "finished rmc_batching_plant: 31\n",
      "Reading From rmu_units\n",
      "finished rmu_units: 32\n",
      "Reading From sanitary_fixtures\n",
      "finished sanitary_fixtures: 33\n",
      "Reading From skid_steer_loader\n",
      "finished skid_steer_loader: 34\n",
      "Reading From smoke_detectors\n",
      "finished smoke_detectors: 35\n",
      "Reading From split_units\n",
      "finished split_units: 36\n",
      "Reading From structural_steel_channel\n",
      "finished structural_steel_channel: 37\n",
      "Reading From switch_boards_and_switches\n",
      "finished switch_boards_and_switches: 38\n",
      "Reading From texture_paint\n",
      "finished texture_paint: 39\n",
      "Reading From threaded_rod\n",
      "finished threaded_rod: 40\n",
      "Reading From transit_mixer\n",
      "finished transit_mixer: 41\n",
      "Reading From vcb_panel\n",
      "finished vcb_panel: 42\n",
      "Reading From vitrified_tiles\n",
      "finished vitrified_tiles: 43\n",
      "Reading From vrf_units\n",
      "finished vrf_units: 44\n",
      "Reading From water_tank\n",
      "finished water_tank: 45\n",
      "Reading From wheel_loader\n",
      "finished wheel_loader: 46\n",
      "Reading From wood_primer\n",
      "finished wood_primer: 47\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(data_dir)\n",
    "im_id = 0\n",
    "anno_id = 0\n",
    "category_id = 0\n",
    "\n",
    "for category in folders:\n",
    "    if os.path.isfile(f\"data/{category}/updated_coco.json\"):\n",
    "        print(f\"Skipping {category} as file already updated\")\n",
    "        category_id += 1\n",
    "        continue\n",
    "    print(f\"Reading From {category}\")\n",
    "    data = json.load(open(os.path.join(data_dir, f\"{category}/coco.json\")))\n",
    "    k = 0\n",
    "    images_info = data[\"images\"]\n",
    "\n",
    "    res_file = {\"info\": {\"description\": \"Construction Material Panoptic Segmentation & Object Detection Data\",\"url\": \"\",\"version\": \"1.0\",\"year\": 2021,\"contributor\": \"https://theschoolof.ai/\",\"date_created\": \"AUG 2021\",},\n",
    "                \"licenses\": [{\"name\": \"\", \"id\": 0, \"url\": \"\"}],\n",
    "                \"images\": [],\n",
    "                \"annotations\": [],\n",
    "                \"categories\": [{\"supercategory\": \"construction material\",\"isthing\": 1,\"id\": category_id, \"name\": category,}],}\n",
    "    \n",
    "    for i in range(len(images_info)):\n",
    "        image = images_info[i]\n",
    "        im_name = image[\"file_name\"]\n",
    "        image_id = image[\"id\"]\n",
    "        h, w = image[\"height\"], image[\"width\"]\n",
    "\n",
    "        im_path = os.path.join(f\"data/{category}/images\", im_name)\n",
    "        if not os.path.isfile(im_path):\n",
    "            continue\n",
    "        im = Image.open(im_path).convert(\"RGB\")\n",
    "\n",
    "        if im.size != (w, h):\n",
    "            continue\n",
    "        if k == len(data[\"annotations\"]):  # this cond'n is true then are more images then annotions\n",
    "            break\n",
    "\n",
    "        masks, result = detect_masks(im)\n",
    "        print(f\"Image {im_id}\", end=\"\\r\")\n",
    "        lab_mask_corr = []\n",
    "        flag = False\n",
    "        while True:\n",
    "            if (k < len(data[\"annotations\"]) and data[\"annotations\"][k][\"image_id\"] == image_id):\n",
    "                flag = True\n",
    "                lab_mask_corr.extend(data[\"annotations\"][k][\"segmentation\"])\n",
    "                res_file[\"annotations\"].append({\"id\": anno_id,\n",
    "                                                \"image_id\": im_id,\n",
    "                                                \"category_id\": category_id,\n",
    "                                                \"segmentation\": data[\"annotations\"][k][\"segmentation\"],\n",
    "                                                \"area\": data[\"annotations\"][k][\"area\"],\n",
    "                                                \"bbox\": data[\"annotations\"][k][\"bbox\"],\n",
    "                                                \"iscrowd\": 0,\n",
    "                                                \"attributes\": data[\"annotations\"][k][\"attributes\"],})\n",
    "                k += 1\n",
    "                anno_id += 1\n",
    "            else:\n",
    "                break\n",
    "        # checking lab_mask_corr, for some images no anotations\n",
    "        if flag:\n",
    "            res_file[\"images\"].append({\"id\": im_id,\n",
    "                                       \"file_name\": im_path,\n",
    "                                       \"height\": h,\n",
    "                                       \"width\": w,\n",
    "                                       \"license\": 0,})\n",
    "        if (k < len(data[\"annotations\"]) and result[\"segments_info\"] and lab_mask_corr):\n",
    "\n",
    "            lab_mask = (convert_coco_poly_to_mask([lab_mask_corr], h, w).squeeze().numpy())\n",
    "            for i in range(len(masks)):\n",
    "                mask = masks[i]\n",
    "\n",
    "                mask = remove_overlap(mask, lab_mask)\n",
    "                bbox, cor_seg = get_bbox_segmask(mask, h, w)\n",
    "                if not bbox:\n",
    "                    continue\n",
    "                if result[\"segments_info\"][i][\"isthing\"]:\n",
    "                    # here we are manuplating the our labelled data the, these category_id will be assigned when we will combine it with coco_val\n",
    "                    res_file[\"annotations\"].append({\"id\": anno_id,\n",
    "                                                    \"image_id\": im_id,\n",
    "                                                    \"category_id\": \"assing_later:miscellaneous\",\n",
    "                                                    \"segmentation\": cor_seg,\n",
    "                                                    \"area\": bbox[2] * bbox[3],\n",
    "                                                    \"bbox\": bbox,\n",
    "                                                    \"iscrowd\": 0,\n",
    "                                                    \"attributes\": data[\"annotations\"][k][\"attributes\"],})\n",
    "                    anno_id += 1\n",
    "                else:\n",
    "                    res_file[\"annotations\"].append({\"id\": anno_id,\n",
    "                                                    \"image_id\": im_id,\n",
    "                                                    \"category_id\": \"assing_later:{}\".format(result[\"segments_info\"][i][\"category_id\"]),\n",
    "                                                    \"segmentation\": cor_seg,\n",
    "                                                    \"area\": bbox[2] * bbox[3],\n",
    "                                                    \"bbox\": bbox,\n",
    "                                                    \"iscrowd\": 0,\n",
    "                                                    \"attributes\": data[\"annotations\"][k][\"attributes\"],})\n",
    "                    anno_id += 1\n",
    "        im_id += 1\n",
    "    print(f\"finished {category}: {category_id}\")\n",
    "    category_id += 1\n",
    "\n",
    "    with open(os.path.join(data_dir, f\"{category}/updated_coco.json\"), \"w\") as f:\n",
    "        f.write(json.dumps(res_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46715b-9ffd-47a9-bdf8-1c28e132bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9781523-b448-4cb8-8ed8-4cfb63fb6802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bba2d-8d2f-48ec-ba37-3c7a57fd0d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d20522-3273-43f4-af7a-0df1d463db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2e9bb-1f98-4503-b2b0-e5f6b16e6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
